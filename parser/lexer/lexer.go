package lexer

import (
	"fmt"
	"strings"

	"github.com/expr-lang/expr/file"
)

func Lex(source file.Source) ([]Token, error) {
	l := &lexer{
		source: source,
		tokens: make([]Token, 0),
		start:  0,
		end:    0,
	}
	l.commit()

	for state := root; state != nil; {
		state = state(l)
	}

	if l.err != nil {
		return nil, l.err.Bind(source)
	}

	return l.tokens, nil
}

type lexer struct {
	source     file.Source
	tokens     []Token
	start, end int
	err        *file.Error
}

const eof rune = -1

func (l *lexer) commit() {
	l.start = l.end
}

func (l *lexer) next() rune {
	if l.end >= len(l.source) {
		l.end++
		return eof
	}
	r := l.source[l.end]
	l.end++
	return r
}

func (l *lexer) peek() rune {
	r := l.next()
	l.backup()
	return r
}

func (l *lexer) backup() {
	l.end--
}

func (l *lexer) emit(t Kind) {
	l.emitValue(t, l.word())
}

// æ„é€ ä¸€ä¸ª Token å®ä¾‹ï¼Œå¹¶è¿½åŠ åˆ° l.tokens åˆ‡ç‰‡ä¸­ã€‚
func (l *lexer) emitValue(t Kind, value string) {
	l.tokens = append(l.tokens, Token{
		Location: file.Location{From: l.start, To: l.end}, // è®°å½• token åœ¨æºç ä¸­çš„ä½ç½®ï¼Œç”¨äºé”™è¯¯å®šä½ã€è°ƒè¯•
		Kind:     t,                                       // æ ‡è¯† token ç±»å‹
		Value:    value,                                   // å­˜å‚¨çœŸæ­£çš„ token å­—ç¬¦ä¸²
	})
	l.commit()
}

func (l *lexer) emitEOF() {
	from := l.end - 2
	if from < 0 {
		from = 0
	}
	to := l.end - 1
	if to < 0 {
		to = 0
	}

	l.tokens = append(l.tokens, Token{
		Location: file.Location{From: from, To: to},
		Kind:     EOF,
	})
	l.commit()
}

func (l *lexer) skip() {
	l.commit()
}

func (l *lexer) word() string {
	// TODO: boundary check is NOT needed here, but for some reason CI fuzz tests are failing.
	// l.start å’Œ l.end åº”è¯¥å§‹ç»ˆåœ¨åˆæ³•èŒƒå›´å†…
	if l.start > len(l.source) || l.end > len(l.source) {
		return "__invalid__"
	}
	// å– [start:end] åŒºé—´å†…å®¹ä½œä¸ºå½“å‰ word
	return string(l.source[l.start:l.end])
}

func (l *lexer) accept(valid string) bool {
	// 1) è¯»å–ä¸‹ä¸€ä¸ªå­—ç¬¦ r ï¼Œå¹¶ç§»åŠ¨ end++
	// 2) æ£€æŸ¥å­—ç¬¦ r æ˜¯å¦å­˜åœ¨äº valid ä¸­
	if strings.ContainsRune(valid, l.next()) {
		return true
	}
	// å¦‚æœ r ä¸åœ¨ valid ä¸­ï¼Œå›é€€ end--
	l.backup()
	return false
}

func (l *lexer) acceptRun(valid string) {
	for strings.ContainsRune(valid, l.next()) {
	}
	l.backup()
}

func (l *lexer) skipSpaces() {
	r := l.peek()
	for ; r == ' '; r = l.peek() {
		l.next()
	}
	l.skip()
}

func (l *lexer) acceptWord(word string) bool {
	pos := l.end

	// è·³è¿‡æ‰€æœ‰å‰å¯¼ç©ºç™½å­—ç¬¦
	l.skipSpaces()

	// æ£€æŸ¥åç»­å­—ç¬¦æ˜¯å¦å’Œ word åŒ¹é…ï¼Œä¸åŒ¹é…ç›´æ¥å›æ»šå¹¶è¿”å›
	for _, ch := range word {
		if l.next() != ch {
			l.end = pos // åŒ¹é…å¤±è´¥æ—¶å®Œå…¨å›é€€ï¼Œä¸æ”¹å˜ lexer çŠ¶æ€
			return false
		}
	}

	// ç¡®ä¿å®Œæ•´åŒ¹é…è€Œéå­ä¸²
	if r := l.peek(); r != ' ' && r != eof {
		l.end = pos
		return false
	}

	return true
}

func (l *lexer) error(format string, args ...any) stateFn {
	if l.err == nil { // show first error
		l.err = &file.Error{
			Location: file.Location{
				From: l.end - 1,
				To:   l.end,
			},
			Message: fmt.Sprintf(format, args...),
		}
	}
	return nil
}

func digitVal(ch rune) int {
	switch {
	case '0' <= ch && ch <= '9':
		return int(ch - '0')
	case 'a' <= lower(ch) && lower(ch) <= 'f':
		return int(lower(ch) - 'a' + 10)
	}
	return 16 // larger than any legal digit val
}

func lower(ch rune) rune { return ('a' - 'A') | ch } // returns lower-case ch iff ch is ASCII letter

func (l *lexer) scanDigits(ch rune, base, n int) rune {
	for n > 0 && digitVal(ch) < base {
		ch = l.next()
		n--
	}
	if n > 0 {
		l.error("invalid char escape")
	}
	return ch
}

// åœ¨æ‰«æå­—ç¬¦ä¸²æ—¶ï¼ˆå¦‚ "abc\n123"ï¼‰é‡åˆ°åæ–œæ  \ æ—¶è¢«è°ƒç”¨ï¼Œç”¨äºè§£æå„ç§åˆæ³•çš„è½¬ä¹‰åºåˆ—ï¼Œå¦‚ï¼š
//	- \nï¼ˆæ¢è¡Œï¼‰
//	- \\ï¼ˆåæ–œæ ï¼‰
//	- \x20ï¼ˆåå…­è¿›åˆ¶ï¼‰
//	- \u1234ï¼ˆUnicodeï¼‰
// 	- \U0010FFFFï¼ˆUnicodeï¼‰

// å¸¸è§„è½¬ä¹‰å­—ç¬¦ï¼š
//	\a - å“é“ƒ
//	\b - é€€æ ¼
//	\f - æ¢é¡µ
//	\n - æ¢è¡Œ
//	\r - å›è½¦
//	\t - æ°´å¹³åˆ¶è¡¨ç¬¦
//	\v - å‚ç›´åˆ¶è¡¨ç¬¦
//	\\ - åæ–œæ æœ¬èº«
// è¿™äº›ä¸éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œåªè¦è·³è¿‡å°±å¥½ã€‚

// å…«è¿›åˆ¶è½¬ä¹‰ï¼š
//	\000 ï½ \777
// è¯»å–æœ€å¤š 3 ä¸ªå…«è¿›åˆ¶æ•°ï¼ˆ0~7ï¼‰ï¼Œå¦‚ \141 è¡¨ç¤º a ã€‚

// åå…­è¿›åˆ¶è½¬ä¹‰ï¼š
//	\xFF
// è¯»å– x åçš„ 2 ä¸ªåå…­è¿›åˆ¶æ•°å­—ï¼ˆå¦‚ \x41 è¡¨ç¤º Aï¼‰ã€‚

// Unicode çŸ­æ ¼å¼ï¼š
//	\u1234
// è¯»å– u å 4 ä¸ª hexï¼ˆå¦‚ \u4E2D = "ä¸­"ï¼‰ã€‚

// Unicode é•¿æ ¼å¼ï¼š
//	\U0001F600
// è¯»å– U å 8 ä¸ª hexï¼ˆå¦‚ \U0001F600 è¡¨æƒ…ğŸ˜€ï¼‰ã€‚

// ç¤ºä¾‹
//
// å¤„ç†å­—ç¬¦ä¸² "a\\b\x41\u4e2d"ï¼š
//   - a - æ™®é€šå­—ç¬¦
//   - \\ - è½¬ä¹‰ä¸ºåæ–œæ 
//   - b - æ™®é€šå­—ç¬¦
//   - \x41 - è½¬ä¹‰ä¸ºå­—æ¯'A'
//   - \u4e2d - è½¬ä¹‰ä¸ºä¸­æ–‡"ä¸­"
//
// æœ€ç»ˆå­—ç¬¦ä¸²å€¼ä¸ºï¼ša\bAä¸­
func (l *lexer) scanEscape(quote rune) rune {
	ch := l.next() // read character after '/'
	switch ch {
	case 'a', 'b', 'f', 'n', 'r', 't', 'v', '\\', quote:
		// ç®€å•è½¬ä¹‰åºåˆ— nothing to do
		ch = l.next()
	case '0', '1', '2', '3', '4', '5', '6', '7':
		// å…«è¿›åˆ¶
		ch = l.scanDigits(ch, 8, 3)
	case 'x':
		// åå…­è¿›åˆ¶
		ch = l.scanDigits(l.next(), 16, 2)
	case 'u':
		// 4 ä½åå…­è¿›åˆ¶ Unicode
		ch = l.scanDigits(l.next(), 16, 4)
	case 'U':
		// 8 ä½åå…­è¿›åˆ¶ Unicode
		ch = l.scanDigits(l.next(), 16, 8)
	default:
		l.error("invalid char escape")
	}
	return ch
}

func (l *lexer) scanString(quote rune) (n int) {
	// è¯»å–å¼•å·åçš„ç¬¬ä¸€ä¸ªå­—ç¬¦
	ch := l.next() // read character after quote
	// è¿›å…¥å¾ªç¯ï¼Œç›´åˆ°é‡åˆ°åŒ¹é…çš„ç»“æŸå¼•å·
	for ch != quote {
		// å¦‚æœé‡åˆ°æ¢è¡Œç¬¦æˆ–æ–‡ä»¶ç»“æŸç¬¦ï¼Œè¡¨ç¤ºå­—ç¬¦ä¸²æœªæ­£ç¡®ç»ˆæ­¢
		if ch == '\n' || ch == eof {
			l.error("literal not terminated")
			return
		}

		// é‡åˆ°åæ–œæ  \ æ—¶ï¼Œè°ƒç”¨ scanEscape å¤„ç†è½¬ä¹‰åºåˆ—ï¼Œè¿”å›è½¬ä¹‰å¤„ç†åçš„ä¸‹ä¸€ä¸ªå­—ç¬¦
		if ch == '\\' {
			ch = l.scanEscape(quote)
		} else {
			// æ™®é€šå­—ç¬¦åˆ™ç›´æ¥è¯»å–ä¸‹ä¸€ä¸ªå­—ç¬¦
			ch = l.next()
		}

		// è®¡æ•°
		n++
	}
	return
}

func (l *lexer) scanRawString(quote rune) (n int) {
	ch := l.next() // read character after back tick
	for ch != quote {
		if ch == eof {
			l.error("literal not terminated")
			return
		}
		ch = l.next()
		n++
	}
	l.emitValue(String, string(l.source[l.start+1:l.end-1]))
	return
}
